# Claire - Code Logic And Inspection using Reasoning Engine

![Spring Boot](https://img.shields.io/badge/Backend-Spring%20Boot-green) ![Angular](https://img.shields.io/badge/Frontend-Angular-red) ![AI](https://img.shields.io/badge/AI-Local%20%2F%20Cloud-purple)

**Claire** is a code analysis platform developed as a support tool for my degree thesis, supervised by Prof. Emiliano Alessio Tramontana in Computer Science at the University of Catania. 

The primary research objective of this project is to benchmark and compare the quality of code analysis generated by Large Language Models (LLMs) against traditional static analysis tools like SonarQube.

**How it works:** The platform allows users to upload source code and subject them to targeted analysis (e.g., security, readability, refactoring). The backend (Spring Boot) orchestrates the inference using AI models‚Äîcurrently supporting Ollama (local) and Google (cloud API)‚Äîand produces a structured JSON report. The Angular frontend then processes this data to provide a clear, interactive visualization of the results.

---

## ‚ú® Key Features

### Analysis Engine
* **Categories:** Users can customize the analysis scope by selecting specific categories.
* **Prompt subdivision:** when multiple categories are selected for analysis, a single large prompt is not created. This would overload the model and could compromise the quality of the responses. In this case, multiple calls to the model are made sequentially, each integrating the code with a specific prompt in order to focus the model on a single purpose. The results are gradually combined into a single response.
* **Structured Reporting:** The raw JSON output from the AI is parsed and transformed into an organized, readable, and interactive frontend visualization, making it easy to compare results.
* **File vs Snippet:**
  * **File:** designed to upload longer code for analysis and avoid overloading the model. The code in the file will be broken down into smaller chunks, and the analysis will be applied to each one. The chunks begin by picking up part of the code that has already been analysed in order to avoid leaving half-analysed code results as much as possible. At the end of each analysis, any duplicate results are removed.
  * **Snippet:** designed to upload small pieces of code that will be inserted directly into the final prompt without any chunking.

### AI Orchestration
* **Multi-Provider Support:**
    * **Local Models:** Full support for **Ollama** (e.g., Llama 3, Granite Code) for privacy-focused analysis. The user can also edit the model parameters (such as *temperature*, *num_gpu*, *context*)
    * **Cloud Models:** Integration with external APIs (e.g., **Google Gemini**) for high-performance and fastest inference.

---

## üöÄ Installation & Setup

### üê≥ Docker installation

When using the Docker installation, there may be issues with Ollama integration.

1.  **Configure Environment:**
    Navigate to the project root directory. Create a file named `.env` by copying the example template:
    
    ```bash
    cp .env.example .env
    ```
    
    Open the `.env` file and verify the configuration (Database passwords, Encryption keys, and Ollama URL).
    > **Note for Ollama Users:** If Ollama is running on your host machine (not in Docker), ensure `OLLAMA_URL` is set to `http://host.docker.internal:11434` (for Mac/Windows) or `http://127.0.0.1:11434` (for Linux) to allow the container to access your local service.

2.  **Build and Run:**
    Run the following command to build images and start services:

    ```bash
    docker-compose up --build
    ```

3.  **Access the Application:**
    * **Frontend:** [http://localhost:4201](http://localhost:4201)
    * **Backend API:** [http://localhost:8080](http://localhost:8080)

---

### üóÇÔ∏è Standalone Installation

### Prerequisites

Ensure you have the following installed on your machine:
* **Java JDK 21**
* **Node.js** (v18 or higher) & **NPM**
* **MySQL Server** (v8.0+)
* **Git**
* *(Optional)* **Ollama** running locally for local AI inference.

---

### 1. Clone the Repository

Open your terminal and clone the project:

```bash
git clone [https://github.com/zBoringDrop/Claire.git](https://github.com/zBoringDrop/Claire.git)
cd Claire
```

### 2. Database setup

Before running the backend, create an empty database in MySQL named `claire-db`

```sql
CREATE DATABASE claire-db;
```

### 3. Backend Setup (Spring Boot)
The backend uses environment variables for configuration to ensure security.

Navigate to the backend directory:

```bash
cd backend
```
Configuration: Create your local environment file by copying the example template.

```bash
# Linux / Mac
cp .env.local.example .env.local
```
```bash
# Windows (Command Prompt)
copy .env.local.example .env.local
```
Edit credentials: Open the newly created .env.local file with a text editor and fill in your details:

```properties
# .env.local
SPRING_DATASOURCE_USERNAME=your_mysql_user
SPRING_DATASOURCE_PASSWORD=your_mysql_password

# AI Providers Keys (Optional if using only local models)
OPENAI_KEY=sk-your-api-key-here
```

Run the Server:

```bash
# Linux / Mac
./mvnw spring-boot:run
```
```bash
# Windows
mvnw.cmd spring-boot:run
```
The backend will start on http://localhost:8080

### 4. Frontend Setup (Angular)

Navigate to the folder (keep the backend running):

```bash
cd frontend
```

Install dependencies:

```bash
npm install
```

Start the development server:

```bash
npm start
```
The application will be available at http://localhost:4200.

---

## üî∫ Known Issues
* **Re-Analyze button:** The reAnalyze button on each completed analysis sends a request using the same ID as the tool used, the category IDs and the file ID. If the analysis was performed using models running locally (e.g. Ollama), the current configuration will be considered rather than the one used for that specific analysis.

## üöß To do
* **Cancelling analysis in progress:** It is not yet possible to cancel an analysis while it is in progress. Be careful before starting one!
* **Dashboard page:** After logging in, you will be directed to a dashboard that has not yet been implemented.
* **Stats page:** The statistics section ('stats') has not yet been implemented.
* **Themes:** add a light theme and a dark theme

---

## üìÑ License

Distributed under the **MIT License**. See `LICENSE` for more information.
